# https://github.com/rook/rook/blob/release-1.10/deploy/charts/rook-ceph/values.yaml
resources:
  limits:
    cpu: 0
    memory: 0
  requests:
    cpu: 0
    memory: 0
csi:
  provisionerReplicas: 2
  csiRBDProvisionerResource: |
    - name : csi-provisioner
      resource:
        requests:
          memory: 0
          cpu: 0
        limits:
          memory: 0
          cpu: 0
    - name : csi-resizer
      resource:
        requests:
          memory: 0
          cpu: 0
        limits:
          memory: 0
          cpu: 0
    - name : csi-attacher
      resource:
        requests:
          memory: 0
          cpu: 0
        limits:
          memory: 0
          cpu: 0
    - name : csi-snapshotter
      resource:
        requests:
          memory: 0
          cpu: 0
        limits:
          memory: 0
          cpu: 0
    - name : csi-rbdplugin
      resource:
        requests:
          memory: 0
          cpu: 0
        limits:
          memory: 0
          cpu: 0
    - name : csi-omap-generator
      resource:
        requests:
          memory: 0
          cpu: 0
        limits:
          memory: 0
          cpu: 0
    - name : liveness-prometheus
      resource:
        requests:
          memory: 0
          cpu: 0
        limits:
          memory: 0
          cpu: 100m
  # CEPH CSI RBD plugin resource requirement list, Put here list of resource
  # requests and limits you want to apply for plugin pod
  csiRBDPluginResource: |
    - name : driver-registrar
      resource:
        requests:
          memory: 0
          cpu: 0
        limits:
          memory: 0
          cpu: 0
    - name : csi-rbdplugin
      resource:
        requests:
          memory: 0
          cpu: 0
        limits:
          memory: 0
          cpu: 0
    - name : liveness-prometheus
      resource:
        requests:
          memory: 0
          cpu: 0
        limits:
          memory: 0
          cpu: 0
  # CEPH CSI CephFS provisioner resource requirement list, Put here list of resource
  # requests and limits you want to apply for provisioner pod
  csiCephFSProvisionerResource: |
    - name : csi-provisioner
      resource:
        requests:
          memory: 0
          cpu: 0
        limits:
          memory: 0
          cpu: 0
    - name : csi-resizer
      resource:
        requests:
          memory: 0
          cpu: 0
        limits:
          memory: 0
          cpu: 0
    - name : csi-attacher
      resource:
        requests:
          memory: 0
          cpu: 0
        limits:
          memory: 0
          cpu: 0
    - name : csi-snapshotter
      resource:
        requests:
          memory: 0
          cpu: 0
        limits:
          memory: 0
          cpu: 0
    - name : csi-cephfsplugin
      resource:
        requests:
          memory: 0
          cpu: 0
        limits:
          memory: 0
          cpu: 0
    - name : liveness-prometheus
      resource:
        requests:
          memory: 0
          cpu: 0
        limits:
          memory: 0
          cpu: 0
  # CEPH CSI CephFS plugin resource requirement list, Put here list of resource
  # requests and limits you want to apply for plugin pod
  csiCephFSPluginResource: |
    - name : driver-registrar
      resource:
        requests:
          memory: 0
          cpu: 0
        limits:
          memory: 0
          cpu: 0
    - name : csi-cephfsplugin
      resource:
        requests:
          memory: 0
          cpu: 0
        limits:
          memory: 0
          cpu: 0
    - name : liveness-prometheus
      resource:
        requests:
          memory: 0
          cpu: 0
        limits:
          memory: 0
          cpu: 0
  # CEPH CSI NFS provisioner resource requirement list, Put here list of resource
  # requests and limits you want to apply for provisioner pod
  csiNFSProvisionerResource: |
    - name : csi-provisioner
      resource:
        requests:
          memory: 0
          cpu: 0
        limits:
          memory: 0
          cpu: 0
    - name : csi-nfsplugin
      resource:
        requests:
          memory: 0
          cpu: 0
        limits:
          memory: 0
          cpu: 0
  # CEPH CSI NFS plugin resource requirement list, Put here list of resource
  # requests and limits you want to apply for plugin pod
  csiNFSPluginResource: |
    - name : driver-registrar
      resource:
        requests:
          memory: 0
          cpu: 0
        limits:
          memory: 0
          cpu: 0
    - name : csi-nfsplugin
      resource:
        requests:
          memory: 0
          cpu: 0
        limits:
          memory: 0
          cpu: 0













# https://github.com/rook/rook/blob/release-1.10/deploy/charts/rook-ceph-cluster/values.yaml
# https://github.com/rook/rook/blob/release-1.10/deploy/examples/cluster-test.yaml
configOverride: |
    [global]
    osd_pool_default_size = 1
    mon_warn_on_pool_no_redundancy = false
    bdev_flock_retry = 20
    bluefs_buffered_io = false
    mon_data_avail_warn = 10
cephClusterSpec:
  mon:
    count: 1
    allowMultiplePerNode: true
  mgr:
    count: 1
    allowMultiplePerNode: true
  resources:
    mgr:
      limits:
        cpu: "0"
        memory: "0"
      requests:
        cpu: "0"
        memory: "0"
    mon:
      limits:
        cpu: "0"
        memory: "0"
      requests:
        cpu: "0"
        memory: "0"
    osd:
      limits:
        cpu: "0"
        memory: "0"
      requests:
        cpu: "0"
        memory: "0"
    prepareosd:
      # limits: It is not recommended to set limits on the OSD prepare job since it's a one-time burst for memory
      # that must be allowed to complete without an OOM kill
      requests:
        cpu: "0"
        memory: "0"
    mgr-sidecar:
      limits:
        cpu: "0"
        memory: "0"
      requests:
        cpu: "0"
        memory: "0"
    crashcollector:
      limits:
        cpu: "0"
        memory: "0"
      requests:
        cpu: "0"
        memory: "0"
    logcollector:
      limits:
        cpu: "0"
        memory: "0"
      requests:
        cpu: "0"
        memory: "0"
    cleanup:
      limits:
        cpu: "0"
        memory: "0"
      requests:
        cpu: "0"
        memory: "0"
ingress:
  dashboard:
    annotations:
      nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
      nginx.ingress.kubernetes.io/server-snippet: |
        proxy_ssl_verify off;
    host:
      name: ceph-dashboard.selfmade4u.de
    tls:
      - hosts:
        - ceph-dashboard.selfmade4u.de


cephBlockPools:
  - name: ceph-blockpool
    # see https://github.com/rook/rook/blob/master/Documentation/CRDs/Block-Storage/ceph-block-pool-crd.md#spec for available configuration
    spec:
      failureDomain: host
      replicated:
        size: 1
    storageClass:
      enabled: true
      name: ceph-block
      isDefault: true
      reclaimPolicy: Delete
      allowVolumeExpansion: true
      mountOptions: []
      # see https://github.com/rook/rook/blob/master/Documentation/ceph-block.md#provision-storage for available configuration
      parameters:
        # (optional) mapOptions is a comma-separated list of map options.
        # For krbd options refer
        # https://docs.ceph.com/docs/master/man/8/rbd/#kernel-rbd-krbd-options
        # For nbd options refer
        # https://docs.ceph.com/docs/master/man/8/rbd-nbd/#options
        # mapOptions: lock_on_read,queue_depth=1024

        # (optional) unmapOptions is a comma-separated list of unmap options.
        # For krbd options refer
        # https://docs.ceph.com/docs/master/man/8/rbd/#kernel-rbd-krbd-options
        # For nbd options refer
        # https://docs.ceph.com/docs/master/man/8/rbd-nbd/#options
        # unmapOptions: force

        # RBD image format. Defaults to "2".
        imageFormat: "2"
        # RBD image features. Available for imageFormat: "2". CSI RBD currently supports only `layering` feature.
        imageFeatures: layering
        # The secrets contain Ceph admin credentials.
        csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
        csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph
        csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
        csi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph
        csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
        csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph
        # Specify the filesystem type of the volume. If not specified, csi-provisioner
        # will set default as `ext4`. Note that `xfs` is not recommended due to potential deadlock
        # in hyperconverged settings where the volume is mounted on the same node as the osds.
        csi.storage.k8s.io/fstype: ext4

cephFileSystems:
  - name: ceph-filesystem
    # see https://github.com/rook/rook/blob/master/Documentation/CRDs/Shared-Filesystem/ceph-filesystem-crd.md#filesystem-settings for available configuration
    spec:
      metadataPool:
        replicated:
          size: 1
      dataPools:
        - failureDomain: host
          replicated:
            size: 1
          # Optional and highly recommended, 'data0' by default, see https://github.com/rook/rook/blob/master/Documentation/CRDs/Shared-Filesystem/ceph-filesystem-crd.md#pools
          name: data0
      metadataServer:
        activeCount: 1
        activeStandby: true
        resources:
          limits:
            cpu: "0"
            memory: "0"
          requests:
            cpu: "0"
            memory: "0"
        priorityClassName: system-cluster-critical
    storageClass:
      enabled: true
      isDefault: false
      name: ceph-filesystem
      # (Optional) specify a data pool to use, must be the name of one of the data pools above, 'data0' by default
      pool: data0
      reclaimPolicy: Delete
      allowVolumeExpansion: true
      mountOptions: []
      # see https://github.com/rook/rook/blob/master/Documentation/ceph-filesystem.md#provision-storage for available configuration
      parameters:
        # The secrets contain Ceph admin credentials.
        csi.storage.k8s.io/provisioner-secret-name: rook-csi-cephfs-provisioner
        csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph
        csi.storage.k8s.io/controller-expand-secret-name: rook-csi-cephfs-provisioner
        csi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph
        csi.storage.k8s.io/node-stage-secret-name: rook-csi-cephfs-node
        csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph
        # Specify the filesystem type of the volume. If not specified, csi-provisioner
        # will set default as `ext4`. Note that `xfs` is not recommended due to potential deadlock
        # in hyperconverged settings where the volume is mounted on the same node as the osds.
        csi.storage.k8s.io/fstype: ext4

cephFileSystemVolumeSnapshotClass:
  enabled: false
  name: ceph-filesystem
  isDefault: true
  deletionPolicy: Delete
  annotations: {}
  labels: {}
  # see https://rook.io/docs/rook/latest/ceph-csi-snapshot.html#cephfs-snapshots for available configuration
  parameters: {}

cephBlockPoolsVolumeSnapshotClass:
  enabled: false
  name: ceph-block
  isDefault: false
  deletionPolicy: Delete
  annotations: {}
  labels: {}
  # see https://rook.io/docs/rook/latest/ceph-csi-snapshot.html#rbd-snapshots for available configuration
  parameters: {}

cephObjectStores:
  - name: ceph-objectstore
    # see https://github.com/rook/rook/blob/master/Documentation/CRDs/Object-Storage/ceph-object-store-crd.md#object-store-settings for available configuration
    spec:
      metadataPool:
        failureDomain: host
        replicated:
          size: 1
      dataPool:
        failureDomain: host
        erasureCoded:
          dataChunks: 1
          codingChunks: 0
      preservePoolsOnDelete: true
      gateway:
        port: 80
        resources:
          limits:
            cpu: "0"
            memory: "0"
          requests:
            cpu: "0"
            memory: "0"
        # securePort: 443
        # sslCertificateRef:
        instances: 1
        priorityClassName: system-cluster-critical
      healthCheck:
        bucket:
          interval: 60s
    storageClass:
      enabled: true
      name: ceph-bucket
      reclaimPolicy: Delete
      # see https://github.com/rook/rook/blob/master/Documentation/ceph-object-bucket-claim.md#storageclass for available configuration
      parameters:
        # note: objectStoreNamespace and objectStoreName are configured by the chart
        region: us-east-1